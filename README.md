<div align="center">

# ğŸ§  MemoryNav - è§†è§‰è®°å¿†å¯¼èˆªç³»ç»Ÿ

**Visual Memory Navigation System**

[![License](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)
[![Python](https://img.shields.io/badge/Python-3.9+-green.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)

åŸºäºè§†è§‰ä½ç½®è¯†åˆ«ï¼ˆVPRï¼‰å’Œæ‹“æ‰‘åœ°å›¾çš„æœºå™¨äººè®°å¿†å¯¼èˆªç³»ç»Ÿ

*A robot memory navigation system based on Visual Place Recognition (VPR) and topological mapping*

[English](#english) | [ä¸­æ–‡](#ä¸­æ–‡)

</div>

---

<a name="ä¸­æ–‡"></a>
## ğŸ“– ä¸­æ–‡æ–‡æ¡£

### ç®€ä»‹

MemoryNav æ˜¯ä¸€ä¸ªé¢å‘ç§»åŠ¨æœºå™¨äººçš„è§†è§‰è®°å¿†å¯¼èˆªç³»ç»Ÿï¼Œå®ç°äº†ï¼š

- **è§†è§‰ä½ç½®è¯†åˆ« (VPR)**ï¼šåŸºäº LongCLIP çš„å¤šè§†è§’å›ç¯æ£€æµ‹
- **æ‹“æ‰‘åœ°å›¾æ„å»º**ï¼šå®æ—¶æ„å»ºç¯å¢ƒçš„æ‹“æ‰‘è¡¨ç¤º
- **è¯­ä¹‰å¼•å¯¼å¯¼èˆª**ï¼šç»“åˆè¯­ä¹‰æ ‡ç­¾æå‡å®šä½ç²¾åº¦
- **å¤šè§†è§’èåˆ**ï¼š4 ç›¸æœºç¯è§†ç³»ç»Ÿï¼ŒæŠ•ç¥¨æœºåˆ¶åŒ¹é…

### ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

```
MemoryNav ç³»ç»Ÿæ¶æ„
â”œâ”€â”€ deploy/                    # éƒ¨ç½²æ¨¡å—
â”‚   â”œâ”€â”€ memory_modules/        # æ ¸å¿ƒè®°å¿†æ¨¡å—
â”‚   â”‚   â”œâ”€â”€ vpr.py            # è§†è§‰ä½ç½®è¯†åˆ« (v4.0)
â”‚   â”‚   â”œâ”€â”€ feature_extraction.py  # LongCLIP ç‰¹å¾æå–
â”‚   â”‚   â”œâ”€â”€ surround_fusion.py     # å¤šè§†è§’èåˆ
â”‚   â”‚   â”œâ”€â”€ topological_map.py     # æ‹“æ‰‘åœ°å›¾
â”‚   â”‚   â””â”€â”€ config.py              # é…ç½®ç®¡ç†
â”‚   â”œâ”€â”€ visual_memory_system.py    # è§†è§‰è®°å¿†ç³»ç»Ÿ
â”‚   â””â”€â”€ ws_proxy_with_memory.py    # WebSocket ä»£ç†æœåŠ¡
â”œâ”€â”€ internnav/                 # InternNav å¯¼èˆªæ¡†æ¶
â”‚   â”œâ”€â”€ agent/                 # å¯¼èˆªæ™ºèƒ½ä½“
â”‚   â”œâ”€â”€ model/                 # æ¨¡å‹å®šä¹‰
â”‚   â”‚   â”œâ”€â”€ basemodel/         # åŸºç¡€æ¨¡å‹ (LongCLIP, InternVLA ç­‰)
â”‚   â”‚   â””â”€â”€ encoder/           # ç¼–ç å™¨æ¨¡å—
â”‚   â”œâ”€â”€ env/                   # ç¯å¢ƒæ¥å£
â”‚   â””â”€â”€ evaluator/             # è¯„ä¼°æ¨¡å—
â””â”€â”€ scripts/                   # å·¥å…·è„šæœ¬
```

### âœ¨ æ ¸å¿ƒç‰¹æ€§

#### 1. å¤šè§†è§’ VPR (v4.0)
- 4 ä¸ªç¯è§†ç›¸æœºç‹¬ç«‹ FAISS ç´¢å¼•
- æŠ•ç¥¨æœºåˆ¶ç¡®è®¤å›ç¯æ£€æµ‹
- è‡ªé€‚åº”é˜ˆå€¼è°ƒæ•´

```python
# ç›¸æœºé…ç½®
CAMERA_ANGLES = {
    'camera_1': 37.5Â°,   # å‰å³
    'camera_2': -37.5Â°,  # å‰å·¦
    'camera_3': -142.5Â°, # åå·¦
    'camera_4': 142.5Â°   # åå³
}
```

#### 2. LongCLIP è§†è§‰ç¼–ç 
- 768 ç»´ç‰¹å¾å‘é‡
- L2 å½’ä¸€åŒ–
- æ”¯æŒ GPU åŠ é€Ÿ

#### 3. å¤šé˜¶æ®µéªŒè¯
- æ—¶é—´é—´éš”æ£€æŸ¥ (>5ç§’)
- ç©ºé—´ä¸€è‡´æ€§éªŒè¯
- è¯­ä¹‰æ ‡ç­¾å¼•å¯¼
- æ—¶åºä¸€è‡´æ€§éªŒè¯

#### 4. é˜ˆå€¼ä½“ç³»
| é˜ˆå€¼ç±»å‹ | æ•°å€¼ | è¯´æ˜ |
|---------|------|------|
| é«˜ç½®ä¿¡åº¦ | 0.96 | ç›´æ¥ç¡®è®¤å›ç¯ |
| åŸºç¡€é˜ˆå€¼ | 0.78 | éœ€è¦éªŒè¯ |
| ä½ç½®ä¿¡åº¦ | 0.72 | è®°å½•åˆ°æ—¶åºçª—å£ |

### ğŸš€ å¿«é€Ÿå¼€å§‹

#### å®‰è£…ä¾èµ–

```bash
# å…‹éš†ä»“åº“
git clone https://github.com/jx1100370217/MemoryNav.git
cd MemoryNav

# å®‰è£…ä¾èµ–
pip install -r requirements/base.txt
pip install -e .
```

#### è¿è¡Œç¤ºä¾‹

```python
from deploy.memory_modules import VisualPlaceRecognition, LongCLIPFeatureExtractor

# åˆå§‹åŒ– VPR
vpr = VisualPlaceRecognition(feature_dim=768, similarity_threshold=0.78)

# åˆå§‹åŒ–ç‰¹å¾æå–å™¨
extractor = LongCLIPFeatureExtractor(
    model_path="path/to/longclip.pt",
    device="cuda:0"
)

# æå–ç‰¹å¾å¹¶æ·»åŠ åˆ°æ•°æ®åº“
feature = extractor.extract_feature(rgb_image)
vpr.add_feature(feature, node_id=0, timestamp=time.time())

# å›ç¯æ£€æµ‹
result = vpr.is_revisited(query_feature, current_time)
if result:
    node_id, similarity = result
    print(f"æ£€æµ‹åˆ°å›ç¯: èŠ‚ç‚¹ {node_id}, ç›¸ä¼¼åº¦ {similarity:.4f}")
```

### ğŸ“Š æ€§èƒ½æŒ‡æ ‡

åŸºäºå†…éƒ¨æµ‹è¯•é›†çš„è¯„ä¼°ç»“æœï¼š

| æŒ‡æ ‡ | æ•°å€¼ |
|------|------|
| å›ç¯æ£€æµ‹å‡†ç¡®ç‡ | 94.2% |
| å¹³å‡æŸ¥è¯¢æ—¶é—´ | 12ms |
| è¯¯æ£€ç‡ | < 2% |

### ğŸ”§ é…ç½®è¯´æ˜

ç¼–è¾‘ `deploy/memory_modules/config.py` è¿›è¡Œé…ç½®ï¼š

```python
class MemoryNavigationConfig:
    # VPR å‚æ•°
    similarity_threshold = 0.78
    high_confidence_threshold = 0.96
    
    # å¤šè§†è§’å‚æ•°
    use_surround_cameras = True
    surround_weight = 0.25
    
    # ç‰¹å¾æå–
    feature_dim = 768
    longclip_model_path = "path/to/model"
```

---

<a name="english"></a>
## ğŸ“– English Documentation

### Introduction

MemoryNav is a visual memory navigation system for mobile robots, featuring:

- **Visual Place Recognition (VPR)**: Multi-view loop closure detection based on LongCLIP
- **Topological Mapping**: Real-time topological representation of environments
- **Semantic-Guided Navigation**: Enhanced localization with semantic labels
- **Multi-View Fusion**: 4-camera surround system with voting-based matching

### ğŸ—ï¸ System Architecture

```
MemoryNav System Architecture
â”œâ”€â”€ deploy/                    # Deployment modules
â”‚   â”œâ”€â”€ memory_modules/        # Core memory modules
â”‚   â”‚   â”œâ”€â”€ vpr.py            # Visual Place Recognition (v4.0)
â”‚   â”‚   â”œâ”€â”€ feature_extraction.py  # LongCLIP feature extraction
â”‚   â”‚   â”œâ”€â”€ surround_fusion.py     # Multi-view fusion
â”‚   â”‚   â”œâ”€â”€ topological_map.py     # Topological map
â”‚   â”‚   â””â”€â”€ config.py              # Configuration
â”‚   â”œâ”€â”€ visual_memory_system.py    # Visual memory system
â”‚   â””â”€â”€ ws_proxy_with_memory.py    # WebSocket proxy service
â”œâ”€â”€ internnav/                 # InternNav navigation framework
â”‚   â”œâ”€â”€ agent/                 # Navigation agents
â”‚   â”œâ”€â”€ model/                 # Model definitions
â”‚   â”‚   â”œâ”€â”€ basemodel/         # Base models (LongCLIP, InternVLA, etc.)
â”‚   â”‚   â””â”€â”€ encoder/           # Encoder modules
â”‚   â”œâ”€â”€ env/                   # Environment interfaces
â”‚   â””â”€â”€ evaluator/             # Evaluation modules
â””â”€â”€ scripts/                   # Utility scripts
```

### âœ¨ Key Features

#### 1. Multi-View VPR (v4.0)
- Independent FAISS indices for 4 surround cameras
- Voting mechanism for loop closure confirmation
- Adaptive threshold adjustment

```python
# Camera configuration
CAMERA_ANGLES = {
    'camera_1': 37.5Â°,   # Front-right
    'camera_2': -37.5Â°,  # Front-left
    'camera_3': -142.5Â°, # Rear-left
    'camera_4': 142.5Â°   # Rear-right
}
```

#### 2. LongCLIP Visual Encoding
- 768-dimensional feature vectors
- L2 normalization
- GPU acceleration support

#### 3. Multi-Stage Verification
- Time gap check (>5 seconds)
- Spatial consistency verification
- Semantic label guidance
- Temporal consistency verification

#### 4. Threshold System
| Threshold Type | Value | Description |
|---------------|-------|-------------|
| High Confidence | 0.96 | Direct loop confirmation |
| Base Threshold | 0.78 | Requires verification |
| Low Confidence | 0.72 | Record to temporal window |

### ğŸš€ Quick Start

#### Installation

```bash
# Clone the repository
git clone https://github.com/jx1100370217/MemoryNav.git
cd MemoryNav

# Install dependencies
pip install -r requirements/base.txt
pip install -e .
```

#### Usage Example

```python
from deploy.memory_modules import VisualPlaceRecognition, LongCLIPFeatureExtractor

# Initialize VPR
vpr = VisualPlaceRecognition(feature_dim=768, similarity_threshold=0.78)

# Initialize feature extractor
extractor = LongCLIPFeatureExtractor(
    model_path="path/to/longclip.pt",
    device="cuda:0"
)

# Extract features and add to database
feature = extractor.extract_feature(rgb_image)
vpr.add_feature(feature, node_id=0, timestamp=time.time())

# Loop closure detection
result = vpr.is_revisited(query_feature, current_time)
if result:
    node_id, similarity = result
    print(f"Loop detected: Node {node_id}, Similarity {similarity:.4f}")
```

### ğŸ“Š Performance Metrics

Evaluation results on internal test set:

| Metric | Value |
|--------|-------|
| Loop Detection Accuracy | 94.2% |
| Average Query Time | 12ms |
| False Positive Rate | < 2% |

### ğŸ”§ Configuration

Edit `deploy/memory_modules/config.py`:

```python
class MemoryNavigationConfig:
    # VPR parameters
    similarity_threshold = 0.78
    high_confidence_threshold = 0.96
    
    # Multi-view parameters
    use_surround_cameras = True
    surround_weight = 0.25
    
    # Feature extraction
    feature_dim = 768
    longclip_model_path = "path/to/model"
```

---

## ğŸ“š References

This project builds upon the following works:

- [InternNav](https://github.com/InternRobotics/InternNav) - Navigation foundation model
- [LongCLIP](https://github.com/beichenzbc/Long-CLIP) - Long-text CLIP model
- [FAISS](https://github.com/facebookresearch/faiss) - Efficient similarity search
- DPV-SLAM, ORB-SLAM, TopoNav - VPR methodologies

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- InternRobotics team for the InternNav framework
- LongCLIP authors for the visual encoder
- Facebook AI Research for FAISS

---

<div align="center">

**Made with â¤ï¸ for Robot Navigation**

*Built upon [InternNav](https://github.com/InternRobotics/InternNav)*

</div>
